{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "To perform sentence classification, and many other classification tasks for NLP, we need to do three main steps:\n",
    "\n",
    "- Preprocessing the data\n",
    "- Prepare the dataloader\n",
    "- Build the model\n",
    "\n",
    "Of course, all of these steps requires a lot of other steps, and also they can include many different solutions. \n",
    "\n",
    "To make you to jumpstart on this task, I will provide you a pretty clean dataset, the Amazon Reviews one, that you can extensively find online, and it's also included in the `torxchtext.datasets` module. \n",
    "\n",
    "For this example, I will use just a little part of it, to give some guidance on how to start, without actually training the whole model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:45.900707Z",
     "start_time": "2021-09-18T17:53:45.431864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import spacy"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:46.495853Z",
     "start_time": "2021-09-18T17:53:45.908197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torchtext.datasets import AmazonReviewFull"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "AmazonReviewFull(root='/Users/franciscovarelacid/Desktop/Strive/datasets')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "amazon_review_full_csv.tar.gz: 644MB [00:13, 48.9MB/s]\n",
      "3000000lines [07:36, 6567.34lines/s]\n",
      "3000000lines [10:41, 4677.75lines/s]\n",
      "650000lines [02:27, 4416.54lines/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<torchtext.datasets.text_classification.TextClassificationDataset at 0x7fdafa84d100>,\n",
       " <torchtext.datasets.text_classification.TextClassificationDataset at 0x7fdaf93d5280>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df = pd.read_csv(\"/Users/franciscovarelacid/Desktop/Strive/datasets/amazon_review_full_csv/train.csv\", nrows=10000, header=None)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck</td>\n",
       "      <td>Gave this to my dad for a gag gift after direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4</td>\n",
       "      <td>Needed additional equipment</td>\n",
       "      <td>We selected this product for my daughter becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>Installation &amp; Rebate Problems</td>\n",
       "      <td>Installation took several hours and was frustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Functionally worthless as of June 2009</td>\n",
       "      <td>The dual tuner feature won't work on this mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Very Bad Experience</td>\n",
       "      <td>Tivo worked for two weeks using the tivo wirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4</td>\n",
       "      <td>hooray for TIVO!</td>\n",
       "      <td>I gave this to my wife for Christmas and now w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                       1  \\\n",
       "0     3                      more like funchuck   \n",
       "1     5                               Inspiring   \n",
       "2     5   The best soundtrack ever to anything.   \n",
       "3     4                        Chrono Cross OST   \n",
       "4     5                     Too good to be true   \n",
       "...  ..                                     ...   \n",
       "9995  4             Needed additional equipment   \n",
       "9996  3          Installation & Rebate Problems   \n",
       "9997  1  Functionally worthless as of June 2009   \n",
       "9998  1                     Very Bad Experience   \n",
       "9999  4                        hooray for TIVO!   \n",
       "\n",
       "                                                      2  \n",
       "0     Gave this to my dad for a gag gift after direc...  \n",
       "1     I hope a lot of people hear this cd. We need m...  \n",
       "2     I'm reading a lot of reviews saying that this ...  \n",
       "3     The music of Yasunori Misuda is without questi...  \n",
       "4     Probably the greatest soundtrack in history! U...  \n",
       "...                                                 ...  \n",
       "9995  We selected this product for my daughter becau...  \n",
       "9996  Installation took several hours and was frustr...  \n",
       "9997  The dual tuner feature won't work on this mode...  \n",
       "9998  Tivo worked for two weeks using the tivo wirel...  \n",
       "9999  I gave this to my wife for Christmas and now w...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:46.540051Z",
     "start_time": "2021-09-18T17:53:46.502284Z"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df.rename({0:\"star\", 1:\"rating1\", 2:\"rating2\"}, axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:46.557125Z",
     "start_time": "2021-09-18T17:53:46.553851Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are going to predict the number of stars a certain product has got based on the semantics of the text, we could merge the title of the review together with the body of the review, just by concatenating them:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df[\"review\"] = df[\"rating1\"] + \" \" +  df[\"rating2\"]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:46.728977Z",
     "start_time": "2021-09-18T17:53:46.709086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>rating1</th>\n",
       "      <th>rating2</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck</td>\n",
       "      <td>Gave this to my dad for a gag gift after direc...</td>\n",
       "      <td>more like funchuck Gave this to my dad for a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4</td>\n",
       "      <td>Needed additional equipment</td>\n",
       "      <td>We selected this product for my daughter becau...</td>\n",
       "      <td>Needed additional equipment We selected this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>Installation &amp; Rebate Problems</td>\n",
       "      <td>Installation took several hours and was frustr...</td>\n",
       "      <td>Installation &amp; Rebate Problems Installation to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Functionally worthless as of June 2009</td>\n",
       "      <td>The dual tuner feature won't work on this mode...</td>\n",
       "      <td>Functionally worthless as of June 2009 The dua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Very Bad Experience</td>\n",
       "      <td>Tivo worked for two weeks using the tivo wirel...</td>\n",
       "      <td>Very Bad Experience Tivo worked for two weeks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4</td>\n",
       "      <td>hooray for TIVO!</td>\n",
       "      <td>I gave this to my wife for Christmas and now w...</td>\n",
       "      <td>hooray for TIVO! I gave this to my wife for Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      star                                 rating1  \\\n",
       "0        3                      more like funchuck   \n",
       "1        5                               Inspiring   \n",
       "2        5   The best soundtrack ever to anything.   \n",
       "3        4                        Chrono Cross OST   \n",
       "4        5                     Too good to be true   \n",
       "...    ...                                     ...   \n",
       "9995     4             Needed additional equipment   \n",
       "9996     3          Installation & Rebate Problems   \n",
       "9997     1  Functionally worthless as of June 2009   \n",
       "9998     1                     Very Bad Experience   \n",
       "9999     4                        hooray for TIVO!   \n",
       "\n",
       "                                                rating2  \\\n",
       "0     Gave this to my dad for a gag gift after direc...   \n",
       "1     I hope a lot of people hear this cd. We need m...   \n",
       "2     I'm reading a lot of reviews saying that this ...   \n",
       "3     The music of Yasunori Misuda is without questi...   \n",
       "4     Probably the greatest soundtrack in history! U...   \n",
       "...                                                 ...   \n",
       "9995  We selected this product for my daughter becau...   \n",
       "9996  Installation took several hours and was frustr...   \n",
       "9997  The dual tuner feature won't work on this mode...   \n",
       "9998  Tivo worked for two weeks using the tivo wirel...   \n",
       "9999  I gave this to my wife for Christmas and now w...   \n",
       "\n",
       "                                                 review  \n",
       "0     more like funchuck Gave this to my dad for a g...  \n",
       "1     Inspiring I hope a lot of people hear this cd....  \n",
       "2     The best soundtrack ever to anything. I'm read...  \n",
       "3     Chrono Cross OST The music of Yasunori Misuda ...  \n",
       "4     Too good to be true Probably the greatest soun...  \n",
       "...                                                 ...  \n",
       "9995  Needed additional equipment We selected this p...  \n",
       "9996  Installation & Rebate Problems Installation to...  \n",
       "9997  Functionally worthless as of June 2009 The dua...  \n",
       "9998  Very Bad Experience Tivo worked for two weeks ...  \n",
       "9999  hooray for TIVO! I gave this to my wife for Ch...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:47.132307Z",
     "start_time": "2021-09-18T17:53:47.105675Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and then of course we can drop the other two columns:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df.drop(columns=[\"rating1\", \"rating2\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:47.699843Z",
     "start_time": "2021-09-18T17:53:47.685235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck Gave this to my dad for a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4</td>\n",
       "      <td>Needed additional equipment We selected this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>Installation &amp; Rebate Problems Installation to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Functionally worthless as of June 2009 The dua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Very Bad Experience Tivo worked for two weeks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4</td>\n",
       "      <td>hooray for TIVO! I gave this to my wife for Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      star                                             review\n",
       "0        3  more like funchuck Gave this to my dad for a g...\n",
       "1        5  Inspiring I hope a lot of people hear this cd....\n",
       "2        5  The best soundtrack ever to anything. I'm read...\n",
       "3        4  Chrono Cross OST The music of Yasunori Misuda ...\n",
       "4        5  Too good to be true Probably the greatest soun...\n",
       "...    ...                                                ...\n",
       "9995     4  Needed additional equipment We selected this p...\n",
       "9996     3  Installation & Rebate Problems Installation to...\n",
       "9997     1  Functionally worthless as of June 2009 The dua...\n",
       "9998     1  Very Bad Experience Tivo worked for two weeks ...\n",
       "9999     4  hooray for TIVO! I gave this to my wife for Ch...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:48.152047Z",
     "start_time": "2021-09-18T17:53:48.131870Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "👏"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `star`column is what we want to predict, given the text of the review. I think we are all Amazon users, and we are all aware of how many stars a rating can have, but let's just double check:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df.star.unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 5, 4, 1, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:53:49.138878Z",
     "start_time": "2021-09-18T17:53:49.129540Z"
    },
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "df.star = df.star.apply(lambda x: int(x) -1)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:52.976714Z",
     "start_time": "2021-09-18T20:18:52.951201Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, now that our data are in order, we need to preprocess them. We can take advantage of spacy for basically of the steps:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.628687Z",
     "start_time": "2021-09-18T20:18:54.542813Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create a function that, given a sentence, it preprocess it by doing:\n",
    "- tokenization\n",
    "- removing stopwords\n",
    "- remove special characters/punctuation\n",
    "- make everything lower case\n",
    "- lemmatize it\n",
    "\n",
    "With spacy, we can do it in a very compact form:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    params sentence: a str containing the sentence we want to preprocess\n",
    "    return the tokens list\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return tokens\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.667517Z",
     "start_time": "2021-09-18T20:18:55.661881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "preprocessing(\"This is an example! Hello\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['example', 'hello']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.729419Z",
     "start_time": "2021-09-18T20:18:55.716703Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The preprocessing phase has not finished yet. In fact, we want to create a neural network, and a neural network works with numbers. In general, computers work with numbers...\n",
    "\n",
    "So we need to use embeddings to transform a sentence into a tensor: the embeddings are usually one-dimensional, and in the following example they will have size 300, that means that if you have a sentence of 10 words (after have it preprocessed), the shape of the sentence will be $10\\times 300$. You will notice another dimension, that is the batch size. So you will train and run a model that receive as input a tensor of shape:\n",
    "\n",
    "`batch_size*length_of_the_sentence*embedding_size`.\n",
    "\n",
    "Let's do things in order:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm, tqdm_notebook"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.785176Z",
     "start_time": "2021-09-18T20:18:55.782315Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are using the whole dataset, you should not need to split the dataset into train and test 'cause it should be already. If not, and if you are using any other dataset, remember to split into train and test (eventually validation)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "train_df, test_df = df.iloc[:8000], df.iloc[8000:]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.833447Z",
     "start_time": "2021-09-18T20:18:55.828371Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the vectors for each token, we are going to use some pretrained embeddings. Specifically, we are going to use the FastText embeddings that you can find at this link https://pytorch.org/text/stable/vocab.html#fasttext .\n",
    "\n",
    "We need to download and load them by doing:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from torchtext.vocab import FastText"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:55.875894Z",
     "start_time": "2021-09-18T20:18:55.872210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "fasttext = FastText(\"simple\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ".vector_cache/wiki.simple.vec: 293MB [00:27, 10.8MB/s]                           \n",
      "  0%|          | 0/111051 [00:00<?, ?it/s]WARNING:torchtext.vocab:Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 111051/111051 [00:22<00:00, 4967.99it/s]\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.351118Z",
     "start_time": "2021-09-18T20:18:55.911030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can run `help(fasttext)` and/or `dir(fasttext)` to get more info about the methods and the attributes this object contains."
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:25:25.972108Z",
     "start_time": "2021-09-18T17:25:25.946631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "dir(fasttext)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'cache',\n",
       " 'dim',\n",
       " 'get_vecs_by_tokens',\n",
       " 'itos',\n",
       " 'stoi',\n",
       " 'unk_init',\n",
       " 'url_base',\n",
       " 'vectors']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.378841Z",
     "start_time": "2021-09-18T20:18:56.376087Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I want to highlight a couple of things:\n",
    "\n",
    "- `dim` is the dimensions of the vectors (in our case it is 300)\n",
    "- `itos` stands for *index to string* and it maps an integer to the corresponding string. The reason for having such a method is that it's much lighter to store integers and use them to index the vectors instead of having a string per word (In addition to that, heuristics can be used so that the most frequent words get lower value for the index, resulting in a better memory management. I know, it sounds like minor things, but the model is going to make billions of operations!)\n",
    "- `stoi` is the opposite: it's a dictionary that given the string returns the index\n",
    "\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T17:26:50.033163Z",
     "start_time": "2021-09-18T17:26:50.028722Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above you can see the embeddings associated with the word \"hello\". Let's inspect the shape:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "fasttext[\"hello\"].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.412987Z",
     "start_time": "2021-09-18T20:18:56.409755Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "300, as anticipated. \n",
    "\n",
    "Let's inspect what's the index associated with \"hello\":"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "fasttext.stoi[\"hello\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2610"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.417035Z",
     "start_time": "2021-09-18T20:18:56.414691Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and viceversa:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "fasttext.stoi"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'</s>': 0,\n",
       " '.': 1,\n",
       " ',': 2,\n",
       " 'the': 3,\n",
       " 'of': 4,\n",
       " \"'\": 5,\n",
       " 'in': 6,\n",
       " '-': 7,\n",
       " 'and': 8,\n",
       " ')': 9,\n",
       " '(': 10,\n",
       " 'a': 11,\n",
       " 'to': 12,\n",
       " 'is': 13,\n",
       " 'was': 14,\n",
       " 'it': 15,\n",
       " 'for': 16,\n",
       " 'on': 17,\n",
       " 's': 18,\n",
       " 'as': 19,\n",
       " 'that': 20,\n",
       " 'from': 21,\n",
       " 'by': 22,\n",
       " 'he': 23,\n",
       " 'are': 24,\n",
       " 'with': 25,\n",
       " 'this': 26,\n",
       " '–': 27,\n",
       " 'be': 28,\n",
       " 'an': 29,\n",
       " 'at': 30,\n",
       " 'or': 31,\n",
       " 'i': 32,\n",
       " 'not': 33,\n",
       " 'people': 34,\n",
       " '}': 35,\n",
       " 'other': 36,\n",
       " 'they': 37,\n",
       " 'his': 38,\n",
       " 'american': 39,\n",
       " 'have': 40,\n",
       " 'has': 41,\n",
       " 'utc': 42,\n",
       " 'also': 43,\n",
       " 'one': 44,\n",
       " 'were': 45,\n",
       " 'which': 46,\n",
       " 'but': 47,\n",
       " 'can': 48,\n",
       " 'talk': 49,\n",
       " 'there': 50,\n",
       " 'first': 51,\n",
       " '#': 52,\n",
       " 'new': 53,\n",
       " 'united': 54,\n",
       " 'about': 55,\n",
       " 'you': 56,\n",
       " 'their': 57,\n",
       " 'may': 58,\n",
       " 'all': 59,\n",
       " 'she': 60,\n",
       " 'd': 61,\n",
       " 'when': 62,\n",
       " 'after': 63,\n",
       " 'had': 64,\n",
       " 'states': 65,\n",
       " 'who': 66,\n",
       " 'made': 67,\n",
       " 'more': 68,\n",
       " 'if': 69,\n",
       " 'born': 70,\n",
       " 'used': 71,\n",
       " 'many': 72,\n",
       " 'city': 73,\n",
       " 'some': 74,\n",
       " 'time': 75,\n",
       " 'websites': 76,\n",
       " 'two': 77,\n",
       " 't': 78,\n",
       " 'its': 79,\n",
       " 'most': 80,\n",
       " 'called': 81,\n",
       " 'b': 82,\n",
       " 'english': 83,\n",
       " 'world': 84,\n",
       " 'been': 85,\n",
       " 'no': 86,\n",
       " '}}': 87,\n",
       " 'her': 88,\n",
       " 'do': 89,\n",
       " 'like': 90,\n",
       " 'only': 91,\n",
       " 'years': 92,\n",
       " 'th': 93,\n",
       " 'known': 94,\n",
       " 'up': 95,\n",
       " 'would': 96,\n",
       " 'into': 97,\n",
       " 'will': 98,\n",
       " 'because': 99,\n",
       " 'so': 100,\n",
       " 'than': 101,\n",
       " 'page': 102,\n",
       " 'name': 103,\n",
       " 'movie': 104,\n",
       " 'national': 105,\n",
       " 'de': 106,\n",
       " '/': 107,\n",
       " 'these': 108,\n",
       " 'very': 109,\n",
       " 'such': 110,\n",
       " 'should': 111,\n",
       " '?': 112,\n",
       " 'them': 113,\n",
       " 'we': 114,\n",
       " 'then': 115,\n",
       " 'team': 116,\n",
       " 'living': 117,\n",
       " 'river': 118,\n",
       " 'part': 119,\n",
       " 'state': 120,\n",
       " '!': 121,\n",
       " 'rowspan': 122,\n",
       " 'music': 123,\n",
       " 'war': 124,\n",
       " 'use': 125,\n",
       " 'year': 126,\n",
       " 'south': 127,\n",
       " 'during': 128,\n",
       " 'over': 129,\n",
       " 'article': 130,\n",
       " 'league': 131,\n",
       " 'january': 132,\n",
       " 'north': 133,\n",
       " 'television': 134,\n",
       " 'british': 135,\n",
       " 'football': 136,\n",
       " 'out': 137,\n",
       " 'actors': 138,\n",
       " 'france': 139,\n",
       " 'university': 140,\n",
       " 'where': 141,\n",
       " 'march': 142,\n",
       " 'what': 143,\n",
       " 'july': 144,\n",
       " 'rd': 145,\n",
       " 'august': 146,\n",
       " 'county': 147,\n",
       " 'make': 148,\n",
       " 'became': 149,\n",
       " 'june': 150,\n",
       " 'between': 151,\n",
       " 'found': 152,\n",
       " 'movies': 153,\n",
       " 'pages': 154,\n",
       " 'discussion': 155,\n",
       " 'm': 156,\n",
       " 'october': 157,\n",
       " 'series': 158,\n",
       " 'december': 159,\n",
       " 'april': 160,\n",
       " 'player': 161,\n",
       " 'september': 162,\n",
       " 'different': 163,\n",
       " 'died': 164,\n",
       " 'style': 165,\n",
       " 'three': 166,\n",
       " 'york': 167,\n",
       " 'group': 168,\n",
       " 'february': 169,\n",
       " 'him': 170,\n",
       " 'november': 171,\n",
       " 'any': 172,\n",
       " 'best': 173,\n",
       " 'just': 174,\n",
       " 'before': 175,\n",
       " 'work': 176,\n",
       " 'now': 177,\n",
       " 'well': 178,\n",
       " 'list': 179,\n",
       " 'see': 180,\n",
       " 'same': 181,\n",
       " 'french': 182,\n",
       " 'john': 183,\n",
       " 'second': 184,\n",
       " 'later': 185,\n",
       " 'history': 186,\n",
       " 'life': 187,\n",
       " 'number': 188,\n",
       " 'being': 189,\n",
       " 'since': 190,\n",
       " 'german': 191,\n",
       " 'related': 192,\n",
       " 'country': 193,\n",
       " 'could': 194,\n",
       " 'u': 195,\n",
       " 'e': 196,\n",
       " 'good': 197,\n",
       " 'birth_place': 198,\n",
       " 'area': 199,\n",
       " 'day': 200,\n",
       " 'often': 201,\n",
       " 'president': 202,\n",
       " 'played': 203,\n",
       " 'c': 204,\n",
       " 'actor': 205,\n",
       " 'king': 206,\n",
       " 'website': 207,\n",
       " 'album': 208,\n",
       " 'language': 209,\n",
       " 'official': 210,\n",
       " 'long': 211,\n",
       " 'wikipedia': 212,\n",
       " 'here': 213,\n",
       " 'did': 214,\n",
       " 'colspan': 215,\n",
       " 'get': 216,\n",
       " 'england': 217,\n",
       " 'century': 218,\n",
       " 'region': 219,\n",
       " 'way': 220,\n",
       " 'how': 221,\n",
       " '%': 222,\n",
       " 'each': 223,\n",
       " 'party': 224,\n",
       " 'west': 225,\n",
       " 'until': 226,\n",
       " 'game': 227,\n",
       " 'my': 228,\n",
       " 'think': 229,\n",
       " 'japan': 230,\n",
       " 'score': 231,\n",
       " 'articles': 232,\n",
       " 'center': 233,\n",
       " 'both': 234,\n",
       " 'released': 235,\n",
       " 'person': 236,\n",
       " 'through': 237,\n",
       " 'family': 238,\n",
       " 'example': 239,\n",
       " 'while': 240,\n",
       " 'left': 241,\n",
       " 'usually': 242,\n",
       " 'however': 243,\n",
       " 'st': 244,\n",
       " 'show': 245,\n",
       " 'won': 246,\n",
       " 'games': 247,\n",
       " 'don': 248,\n",
       " 'main': 249,\n",
       " 'much': 250,\n",
       " 'around': 251,\n",
       " 'international': 252,\n",
       " 'place': 253,\n",
       " 'ii': 254,\n",
       " 'delete': 255,\n",
       " 'templates': 256,\n",
       " 'school': 257,\n",
       " '}}}': 258,\n",
       " 'please': 259,\n",
       " 'california': 260,\n",
       " 'small': 261,\n",
       " 'japanese': 262,\n",
       " 'london': 263,\n",
       " 'singer': 264,\n",
       " 'under': 265,\n",
       " 'f': 266,\n",
       " 'said': 267,\n",
       " 'another': 268,\n",
       " 'former': 269,\n",
       " 'government': 270,\n",
       " 'old': 271,\n",
       " 'children': 272,\n",
       " 'last': 273,\n",
       " 'career': 274,\n",
       " 'east': 275,\n",
       " 'system': 276,\n",
       " 'data': 277,\n",
       " 'jpg': 278,\n",
       " 'cities': 279,\n",
       " 'action': 280,\n",
       " 'back': 281,\n",
       " 'j': 282,\n",
       " 'town': 283,\n",
       " 'started': 284,\n",
       " 'keep': 285,\n",
       " 'does': 286,\n",
       " 'department': 287,\n",
       " 'early': 288,\n",
       " 'named': 289,\n",
       " 'us': 290,\n",
       " 'actress': 291,\n",
       " 'even': 292,\n",
       " 'change': 293,\n",
       " 'several': 294,\n",
       " 'right': 295,\n",
       " 'align': 296,\n",
       " 'great': 297,\n",
       " 'award': 298,\n",
       " 'club': 299,\n",
       " 'against': 300,\n",
       " 'water': 301,\n",
       " 'still': 302,\n",
       " 'your': 303,\n",
       " 'four': 304,\n",
       " 'song': 305,\n",
       " 'important': 306,\n",
       " 'top': 307,\n",
       " 'la': 308,\n",
       " 'general': 309,\n",
       " '+': 310,\n",
       " 'high': 311,\n",
       " 'band': 312,\n",
       " 'live': 313,\n",
       " 'text': 314,\n",
       " 'house': 315,\n",
       " 'large': 316,\n",
       " 'germany': 317,\n",
       " 'district': 318,\n",
       " 'based': 319,\n",
       " 'death': 320,\n",
       " 'template': 321,\n",
       " 'things': 322,\n",
       " 'end': 323,\n",
       " 'me': 324,\n",
       " 'players': 325,\n",
       " 'island': 326,\n",
       " 'image': 327,\n",
       " 'including': 328,\n",
       " 'user': 329,\n",
       " 'using': 330,\n",
       " 'kingdom': 331,\n",
       " 'rock': 332,\n",
       " 'book': 333,\n",
       " 'label': 334,\n",
       " 'near': 335,\n",
       " 'red': 336,\n",
       " 'times': 337,\n",
       " 'need': 338,\n",
       " 'province': 339,\n",
       " 'season': 340,\n",
       " 'go': 341,\n",
       " 'means': 342,\n",
       " 'man': 343,\n",
       " 'title': 344,\n",
       " 'help': 345,\n",
       " 'australia': 346,\n",
       " '}}}}': 347,\n",
       " 'position': 348,\n",
       " 'created': 349,\n",
       " 'set': 350,\n",
       " 'simple': 351,\n",
       " 'communes': 352,\n",
       " 'sometimes': 353,\n",
       " 'politician': 354,\n",
       " 'white': 355,\n",
       " 'given': 356,\n",
       " 'deaths': 357,\n",
       " 'clubs': 358,\n",
       " 'changes': 359,\n",
       " 'type': 360,\n",
       " 'capital': 361,\n",
       " 'countries': 362,\n",
       " 'famous': 363,\n",
       " 'hockey': 364,\n",
       " 'following': 365,\n",
       " 'black': 366,\n",
       " 'species': 367,\n",
       " 'italian': 368,\n",
       " '\"': 369,\n",
       " 'church': 370,\n",
       " 'groups': 371,\n",
       " 'written': 372,\n",
       " 'major': 373,\n",
       " 'single': 374,\n",
       " 'days': 375,\n",
       " 'million': 376,\n",
       " 'line': 377,\n",
       " 'file': 378,\n",
       " 'color': 379,\n",
       " 'saint': 380,\n",
       " 'air': 381,\n",
       " 'america': 382,\n",
       " 'home': 383,\n",
       " 'common': 384,\n",
       " 'army': 385,\n",
       " 'current': 386,\n",
       " 'writer': 387,\n",
       " 'republic': 388,\n",
       " 'those': 389,\n",
       " 'company': 390,\n",
       " 'above': 391,\n",
       " 'word': 392,\n",
       " 'border': 393,\n",
       " 'battle': 394,\n",
       " 'video': 395,\n",
       " 'include': 396,\n",
       " 'own': 397,\n",
       " 'population': 398,\n",
       " 'few': 399,\n",
       " 'college': 400,\n",
       " 'information': 401,\n",
       " 'x': 402,\n",
       " 'down': 403,\n",
       " 'order': 404,\n",
       " 'commune': 405,\n",
       " 'off': 406,\n",
       " 'play': 407,\n",
       " 'know': 408,\n",
       " 'member': 409,\n",
       " 'form': 410,\n",
       " 'canadian': 411,\n",
       " 'point': 412,\n",
       " 'statistics': 413,\n",
       " 'per': 414,\n",
       " 'body': 415,\n",
       " 'take': 416,\n",
       " 'began': 417,\n",
       " 'india': 418,\n",
       " 'roman': 419,\n",
       " 'although': 420,\n",
       " 'park': 421,\n",
       " 'again': 422,\n",
       " 'too': 423,\n",
       " 'without': 424,\n",
       " 'age': 425,\n",
       " 'union': 426,\n",
       " 'built': 427,\n",
       " 'n': 428,\n",
       " 'members': 429,\n",
       " 'women': 430,\n",
       " 'big': 431,\n",
       " 'minister': 432,\n",
       " 'europe': 433,\n",
       " 'popular': 434,\n",
       " 'sea': 435,\n",
       " 'central': 436,\n",
       " 'little': 437,\n",
       " 'become': 438,\n",
       " 'municipality': 439,\n",
       " 'g': 440,\n",
       " 'p': 441,\n",
       " '•': 442,\n",
       " 'land': 443,\n",
       " 'william': 444,\n",
       " 'flag': 445,\n",
       " 'power': 446,\n",
       " 'law': 447,\n",
       " 'australian': 448,\n",
       " 'third': 449,\n",
       " 'next': 450,\n",
       " 'married': 451,\n",
       " 'total': 452,\n",
       " 'due': 453,\n",
       " 'support': 454,\n",
       " 'books': 455,\n",
       " 'request': 456,\n",
       " 'spanish': 457,\n",
       " 'james': 458,\n",
       " 'division': 459,\n",
       " 'every': 460,\n",
       " 'largest': 461,\n",
       " 'close': 462,\n",
       " 'western': 463,\n",
       " 'father': 464,\n",
       " 'short': 465,\n",
       " 'together': 466,\n",
       " 'ice': 467,\n",
       " 'men': 468,\n",
       " 'wrote': 469,\n",
       " 'done': 470,\n",
       " 'reason': 471,\n",
       " 'site': 472,\n",
       " 'northern': 473,\n",
       " 'san': 474,\n",
       " 'five': 475,\n",
       " 'military': 476,\n",
       " 'lot': 477,\n",
       " 'son': 478,\n",
       " 'version': 479,\n",
       " 'george': 480,\n",
       " 'local': 481,\n",
       " 'went': 482,\n",
       " 'px': 483,\n",
       " 'v': 484,\n",
       " 'cup': 485,\n",
       " 'canada': 486,\n",
       " 'want': 487,\n",
       " 'making': 488,\n",
       " 'civil': 489,\n",
       " 'championship': 490,\n",
       " 'occupation': 491,\n",
       " 'young': 492,\n",
       " 'lived': 493,\n",
       " 'sports': 494,\n",
       " 'songs': 495,\n",
       " 'put': 496,\n",
       " 'parts': 497,\n",
       " 'records': 498,\n",
       " 'special': 499,\n",
       " 'took': 500,\n",
       " 'something': 501,\n",
       " 'category': 502,\n",
       " 'period': 503,\n",
       " 'works': 504,\n",
       " 'free': 505,\n",
       " 'r': 506,\n",
       " 'term': 507,\n",
       " 'russian': 508,\n",
       " 'say': 509,\n",
       " 'thought': 510,\n",
       " 'came': 511,\n",
       " 'director': 512,\n",
       " 'others': 513,\n",
       " 'comments': 514,\n",
       " 'better': 515,\n",
       " 'star': 516,\n",
       " 'words': 517,\n",
       " 'moved': 518,\n",
       " 'chicago': 519,\n",
       " 'find': 520,\n",
       " 'prime': 521,\n",
       " 'link': 522,\n",
       " 'modern': 523,\n",
       " 'human': 524,\n",
       " 'public': 525,\n",
       " 'light': 526,\n",
       " 'am': 527,\n",
       " 'makes': 528,\n",
       " '—': 529,\n",
       " 'plays': 530,\n",
       " 'china': 531,\n",
       " 'must': 532,\n",
       " 'islands': 533,\n",
       " 'our': 534,\n",
       " 'though': 535,\n",
       " 'today': 536,\n",
       " 'background': 537,\n",
       " 'killed': 538,\n",
       " 'edit': 539,\n",
       " 'got': 540,\n",
       " 'los': 541,\n",
       " 'art': 542,\n",
       " '&': 543,\n",
       " 'seven': 544,\n",
       " 'story': 545,\n",
       " 'royal': 546,\n",
       " 'en': 547,\n",
       " 'love': 548,\n",
       " 'links': 549,\n",
       " 'below': 550,\n",
       " 'professional': 551,\n",
       " 'italy': 552,\n",
       " 'southern': 553,\n",
       " 'political': 554,\n",
       " 'date': 555,\n",
       " 'class': 556,\n",
       " 'awards': 557,\n",
       " 'non': 558,\n",
       " 'community': 559,\n",
       " 'size': 560,\n",
       " 'space': 561,\n",
       " 'l': 562,\n",
       " 'o': 563,\n",
       " 'david': 564,\n",
       " 'similar': 565,\n",
       " 'enough': 566,\n",
       " 'original': 567,\n",
       " 'robert': 568,\n",
       " 'either': 569,\n",
       " 'changed': 570,\n",
       " 'european': 571,\n",
       " 'sweden': 572,\n",
       " 'earth': 573,\n",
       " 'head': 574,\n",
       " 'wiki': 575,\n",
       " 're': 576,\n",
       " 'held': 577,\n",
       " 'side': 578,\n",
       " 'along': 579,\n",
       " 'look': 580,\n",
       " 'spain': 581,\n",
       " 'charles': 582,\n",
       " '$': 583,\n",
       " 'present': 584,\n",
       " 'footballers': 585,\n",
       " 'summer': 586,\n",
       " 'less': 587,\n",
       " 'stage': 588,\n",
       " 'albums': 589,\n",
       " 'science': 590,\n",
       " 'film': 591,\n",
       " 'might': 592,\n",
       " 'come': 593,\n",
       " 'food': 594,\n",
       " 'never': 595,\n",
       " 'washington': 596,\n",
       " 'published': 597,\n",
       " 'empire': 598,\n",
       " 'emperor': 599,\n",
       " 'prefecture': 600,\n",
       " 'notable': 601,\n",
       " 'computer': 602,\n",
       " 'code': 603,\n",
       " 'record': 604,\n",
       " 'force': 605,\n",
       " 'pakistan': 606,\n",
       " 'seen': 607,\n",
       " 'instead': 608,\n",
       " 'cancer': 609,\n",
       " 'building': 610,\n",
       " 'why': 611,\n",
       " 'tropical': 612,\n",
       " 'court': 613,\n",
       " 'paul': 614,\n",
       " 'mother': 615,\n",
       " 'away': 616,\n",
       " 'indian': 617,\n",
       " 'middle': 618,\n",
       " 'governor': 619,\n",
       " 'money': 620,\n",
       " 'someone': 621,\n",
       " 'texas': 622,\n",
       " 'musical': 623,\n",
       " 'case': 624,\n",
       " 'disease': 625,\n",
       " 'retired': 626,\n",
       " 'six': 627,\n",
       " 'god': 628,\n",
       " 'leader': 629,\n",
       " 'project': 630,\n",
       " 'give': 631,\n",
       " 'voice': 632,\n",
       " 'lake': 633,\n",
       " 'h': 634,\n",
       " 'languages': 635,\n",
       " 'appropriate': 636,\n",
       " 'angeles': 637,\n",
       " 'producer': 638,\n",
       " 'al': 639,\n",
       " 'rights': 640,\n",
       " 'florida': 641,\n",
       " 'station': 642,\n",
       " 'fire': 643,\n",
       " 'shows': 644,\n",
       " 'start': 645,\n",
       " 'field': 646,\n",
       " 'com': 647,\n",
       " 'having': 648,\n",
       " 'radio': 649,\n",
       " 'attack': 650,\n",
       " 'writers': 651,\n",
       " 'once': 652,\n",
       " 'users': 653,\n",
       " 'virginia': 654,\n",
       " 'natural': 655,\n",
       " 'association': 656,\n",
       " 'africa': 657,\n",
       " 'service': 658,\n",
       " 'chinese': 659,\n",
       " 'greek': 660,\n",
       " 'bc': 661,\n",
       " 'bad': 662,\n",
       " 'heart': 663,\n",
       " 'composer': 664,\n",
       " 'eastern': 665,\n",
       " 'going': 666,\n",
       " 'worked': 667,\n",
       " 'hall': 668,\n",
       " 'museum': 669,\n",
       " 'level': 670,\n",
       " 'animals': 671,\n",
       " 'really': 672,\n",
       " 'uk': 673,\n",
       " 'open': 674,\n",
       " 'nominated': 675,\n",
       " 'green': 676,\n",
       " 'role': 677,\n",
       " 'founded': 678,\n",
       " 'musicians': 679,\n",
       " 'footballer': 680,\n",
       " 'office': 681,\n",
       " 'death_place': 682,\n",
       " 'preserved': 683,\n",
       " 'character': 684,\n",
       " 'able': 685,\n",
       " 'isbn': 686,\n",
       " 'deletion': 687,\n",
       " 'mean': 688,\n",
       " 'note': 689,\n",
       " 'blue': 690,\n",
       " 'michael': 691,\n",
       " 'ancient': 692,\n",
       " 'run': 693,\n",
       " 'control': 694,\n",
       " 'places': 695,\n",
       " 'musician': 696,\n",
       " 'lost': 697,\n",
       " 'real': 698,\n",
       " 'full': 699,\n",
       " 'politicians': 700,\n",
       " 'within': 701,\n",
       " 'african': 702,\n",
       " 'formed': 703,\n",
       " 'w': 704,\n",
       " 'idea': 705,\n",
       " 'storm': 706,\n",
       " 'areas': 707,\n",
       " 'names': 708,\n",
       " 'round': 709,\n",
       " 'almost': 710,\n",
       " 'least': 711,\n",
       " 'move': 712,\n",
       " 'hurricane': 713,\n",
       " 'currently': 714,\n",
       " 'teams': 715,\n",
       " 'always': 716,\n",
       " 'edits': 717,\n",
       " 'uses': 718,\n",
       " 'added': 719,\n",
       " 'henry': 720,\n",
       " 'soviet': 721,\n",
       " 'mostly': 722,\n",
       " 'comes': 723,\n",
       " 'late': 724,\n",
       " 'problems': 725,\n",
       " 'paris': 726,\n",
       " 'queen': 727,\n",
       " 'energy': 728,\n",
       " 'probably': 729,\n",
       " 'christian': 730,\n",
       " 'solid': 731,\n",
       " 'prize': 732,\n",
       " 'buildings': 733,\n",
       " 'width': 734,\n",
       " 'served': 735,\n",
       " 'wrestling': 736,\n",
       " 'includes': 737,\n",
       " 'led': 738,\n",
       " 'richard': 739,\n",
       " 'road': 740,\n",
       " 'pop': 741,\n",
       " 'towns': 742,\n",
       " 've': 743,\n",
       " 'km': 744,\n",
       " 'becomes': 745,\n",
       " 'section': 746,\n",
       " 'grand': 747,\n",
       " 'types': 748,\n",
       " 'tv': 749,\n",
       " 'night': 750,\n",
       " 'hard': 751,\n",
       " 'half': 752,\n",
       " 'working': 753,\n",
       " 'problem': 754,\n",
       " 'louis': 755,\n",
       " 'closed': 756,\n",
       " 'wanted': 757,\n",
       " 'subsequent': 758,\n",
       " 'mexico': 759,\n",
       " 'metal': 760,\n",
       " 'child': 761,\n",
       " 'author': 762,\n",
       " 'svg': 763,\n",
       " 'lead': 764,\n",
       " 'taken': 765,\n",
       " 'thomas': 766,\n",
       " 'caused': 767,\n",
       " 'location': 768,\n",
       " 'gave': 769,\n",
       " 'possible': 770,\n",
       " 'municipalities': 771,\n",
       " 'playing': 772,\n",
       " 'mind': 773,\n",
       " 'village': 774,\n",
       " 'wife': 775,\n",
       " 'believe': 776,\n",
       " 'forces': 777,\n",
       " 'council': 778,\n",
       " 'artist': 779,\n",
       " 'iii': 780,\n",
       " 'included': 781,\n",
       " 'final': 782,\n",
       " 'characters': 783,\n",
       " 'peter': 784,\n",
       " 'illinois': 785,\n",
       " 'result': 786,\n",
       " 'received': 787,\n",
       " 'comedy': 788,\n",
       " 'prince': 789,\n",
       " 'drama': 790,\n",
       " 'act': 791,\n",
       " 'map': 792,\n",
       " '>': 793,\n",
       " 'already': 794,\n",
       " 'airport': 795,\n",
       " 'blood': 796,\n",
       " 'produced': 797,\n",
       " 'baseball': 798,\n",
       " 'k': 799,\n",
       " 'months': 800,\n",
       " 'russia': 801,\n",
       " 'race': 802,\n",
       " 'far': 803,\n",
       " 'certain': 804,\n",
       " 'ireland': 805,\n",
       " 'create': 806,\n",
       " 'gold': 807,\n",
       " 'social': 808,\n",
       " 'religion': 809,\n",
       " 'match': 810,\n",
       " 'asia': 811,\n",
       " 'value': 812,\n",
       " 'source': 813,\n",
       " 'society': 814,\n",
       " 'academy': 815,\n",
       " 'according': 816,\n",
       " 'bridge': 817,\n",
       " 'active': 818,\n",
       " 'cause': 819,\n",
       " 'stars': 820,\n",
       " 'further': 821,\n",
       " 'cannot': 822,\n",
       " 'kind': 823,\n",
       " 'co': 824,\n",
       " 'plants': 825,\n",
       " 'writing': 826,\n",
       " 'needed': 827,\n",
       " 'coast': 828,\n",
       " 'meaning': 829,\n",
       " 'nationality': 830,\n",
       " 'guitar': 831,\n",
       " 'let': 832,\n",
       " 'election': 833,\n",
       " 'research': 834,\n",
       " 'editor': 835,\n",
       " 'yes': 836,\n",
       " 'stop': 837,\n",
       " 'olympic': 838,\n",
       " 'brother': 839,\n",
       " 'says': 840,\n",
       " 'police': 841,\n",
       " 'stadium': 842,\n",
       " 'dutch': 843,\n",
       " 'movement': 844,\n",
       " 'especially': 845,\n",
       " 'goals': 846,\n",
       " 'add': 847,\n",
       " 'mountain': 848,\n",
       " 'car': 849,\n",
       " 'daughter': 850,\n",
       " 'block': 851,\n",
       " 'month': 852,\n",
       " 'thanks': 853,\n",
       " 'events': 854,\n",
       " 'event': 855,\n",
       " 'medal': 856,\n",
       " 'range': 857,\n",
       " 'brazil': 858,\n",
       " 'strong': 859,\n",
       " 'numbers': 860,\n",
       " 'spouse': 861,\n",
       " 'female': 862,\n",
       " 'swedish': 863,\n",
       " 'blank': 864,\n",
       " 'ever': 865,\n",
       " 'rivers': 866,\n",
       " 'scottish': 867,\n",
       " 'model': 868,\n",
       " 'scotland': 869,\n",
       " 'length': 870,\n",
       " 'needs': 871,\n",
       " 'aged': 872,\n",
       " 'chemical': 873,\n",
       " 'among': 874,\n",
       " 'latin': 875,\n",
       " 'brown': 876,\n",
       " 'process': 877,\n",
       " 'bay': 878,\n",
       " 'shown': 879,\n",
       " 'news': 880,\n",
       " 'board': 881,\n",
       " 'takes': 882,\n",
       " 'considered': 883,\n",
       " 'actually': 884,\n",
       " 'http': 885,\n",
       " 'woman': 886,\n",
       " 'lists': 887,\n",
       " 'study': 888,\n",
       " 'sure': 889,\n",
       " 'true': 890,\n",
       " 'established': 891,\n",
       " 'switzerland': 892,\n",
       " 'business': 893,\n",
       " 'inside': 894,\n",
       " 'try': 895,\n",
       " 'democratic': 896,\n",
       " 'earlier': 897,\n",
       " 'dead': 898,\n",
       " 'independent': 899,\n",
       " 'lower': 900,\n",
       " 'pope': 901,\n",
       " 'network': 902,\n",
       " 'mary': 903,\n",
       " 'personal': 904,\n",
       " 'developed': 905,\n",
       " 'sound': 906,\n",
       " 'education': 907,\n",
       " 'culture': 908,\n",
       " 'catholic': 909,\n",
       " 'himself': 910,\n",
       " 'longer': 911,\n",
       " 'low': 912,\n",
       " 'edward': 913,\n",
       " 'street': 914,\n",
       " 'rather': 915,\n",
       " 'martin': 916,\n",
       " 'return': 917,\n",
       " 'ocean': 918,\n",
       " 'program': 919,\n",
       " 'le': 920,\n",
       " 'wales': 921,\n",
       " 'sent': 922,\n",
       " 'across': 923,\n",
       " 'castle': 924,\n",
       " 'poet': 925,\n",
       " 'basketball': 926,\n",
       " 'irish': 927,\n",
       " 'singers': 928,\n",
       " 'admin': 929,\n",
       " 'thing': 930,\n",
       " 'development': 931,\n",
       " 'soon': 932,\n",
       " 'editors': 933,\n",
       " 'read': 934,\n",
       " 'mark': 935,\n",
       " 'sources': 936,\n",
       " 'various': 937,\n",
       " 'jersey': 938,\n",
       " 'atlantic': 939,\n",
       " 'vote': 940,\n",
       " 'studio': 941,\n",
       " 'opera': 942,\n",
       " 'students': 943,\n",
       " 'view': 944,\n",
       " 'duke': 945,\n",
       " 'points': 946,\n",
       " '//www': 947,\n",
       " 'sold': 948,\n",
       " 'korean': 949,\n",
       " 'hit': 950,\n",
       " 'federal': 951,\n",
       " 'lives': 952,\n",
       " 'winning': 953,\n",
       " 'aircraft': 954,\n",
       " 'release': 955,\n",
       " 'categories': 956,\n",
       " 'seed': 957,\n",
       " 'usa': 958,\n",
       " 'joined': 959,\n",
       " 'carolina': 960,\n",
       " 'songwriter': 961,\n",
       " 'track': 962,\n",
       " 'ground': 963,\n",
       " 'function': 964,\n",
       " 'elected': 965,\n",
       " 'sportspeople': 966,\n",
       " 'outside': 967,\n",
       " 'sun': 968,\n",
       " 'plant': 969,\n",
       " 'past': 970,\n",
       " 'write': 971,\n",
       " 'etc': 972,\n",
       " 'bar': 973,\n",
       " 'goes': 974,\n",
       " 'opened': 975,\n",
       " 'content': 976,\n",
       " 'available': 977,\n",
       " 'allowed': 978,\n",
       " 'theory': 979,\n",
       " 'winter': 980,\n",
       " 'genre': 981,\n",
       " 'average': 982,\n",
       " 'bands': 983,\n",
       " 'press': 984,\n",
       " 'korea': 985,\n",
       " 'front': 986,\n",
       " 'doesn': 987,\n",
       " 'hot': 988,\n",
       " 'y': 989,\n",
       " 'valley': 990,\n",
       " 'recorded': 991,\n",
       " 'standard': 992,\n",
       " 'located': 993,\n",
       " 'table': 994,\n",
       " 'ten': 995,\n",
       " 'nhl': 996,\n",
       " 'austria': 997,\n",
       " 'highest': 998,\n",
       " 'cross': 999,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.461735Z",
     "start_time": "2021-09-18T20:18:56.443512Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can create and *encoder* which can transform each word into an integer:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def token_encoder(token, vec):\n",
    "    if token == \"<pad>\":\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return vec.stoi[token]\n",
    "        except:\n",
    "            return 0"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.513383Z",
     "start_time": "2021-09-18T20:18:56.510004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def encoder(tokens, vec):\n",
    "    return [token_encoder(token, vec) for token in tokens]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.515942Z",
     "start_time": "2021-09-18T20:18:56.514362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "text = \"Antonio is learning Python\"\n",
    "encoder(preprocessing(text), fasttext)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1660, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.569562Z",
     "start_time": "2021-09-18T20:18:56.559325Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why all those zeros?\n",
    "Well, in the function that we have defined, we have put a try and except, in which we are basically saying: if the word is not in the vocabulary, return the index 0. Clearly, Antonio and Python weren't in the corpus used by FastText!\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What about the `<pad>` thing? \n",
    "\n",
    "Well, not all the reviews have same length, so we need to find a solution for it. Why? Cause our Neural Network is waiting for input that are all of the same size! It needs to know how many weights it needs to initialize!\n",
    "\n",
    "There are several possibilities, but the easiest is to just set a cap with a `max_seq_len` parameter, so that all the reviews that are shorter than that length will be padded by using a vector associated with the padding index, and all the ones that are longer than `max_seq_len` will be just cut.\n",
    "\n",
    "Do you see problems? I actually don't see that much problems for it. I think that the sentiment of a comment can be seen already from the first words of the review.\n",
    "\n",
    "In the encoder part, the `<pad>` is a made up token that we know is very unlikely to be part of the text. To that, I assigned the index 1. \n",
    "\n",
    "You may ask: what does it happen to things at index 0 and 1? Well, let's inspect them:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "fasttext.itos[0], fasttext.itos[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('</s>', '.')"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.598411Z",
     "start_time": "2021-09-18T20:18:56.595358Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and in our preprocessing pipeline they can never appear! So we are fine with that!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create a function for padding:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def padding(list_of_indexes, max_seq_len, padding_index=1):\n",
    "    output = list_of_indexes + (max_seq_len - len(list_of_indexes))*[padding_index]\n",
    "    return output[:max_seq_len]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.625917Z",
     "start_time": "2021-09-18T20:18:56.623200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "text = \"this is a sample review\"\n",
    "list_of_indexes = encoder(preprocessing(text), fasttext)\n",
    "list_of_indexes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3697, 1363]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.636204Z",
     "start_time": "2021-09-18T20:18:56.627044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "padding(list_of_indexes, max_seq_len=10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3697, 1363, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.688320Z",
     "start_time": "2021-09-18T20:18:56.685453Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this way, any sentence shorter than 10 becomes of length 10 and anything longer..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "text = \"this is a sample review this is a sample review this is a sample review this is a sample review this is a sample review v this is a sample review this is a sample review this is a sample review this is a sample review this is a sample review\"\n",
    "list_of_indexes = encoder(preprocessing(text), fasttext)\n",
    "padding(list_of_indexes, max_seq_len=10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3697, 1363, 3697, 1363, 3697, 1363, 3697, 1363, 3697, 1363]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.703768Z",
     "start_time": "2021-09-18T20:18:56.689402Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "...get just cut to ten!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All right. I feel confident enough to say that we have all of what we need for the preprocessing part!\n",
    "\n",
    "Now we need to create the:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Loader\n",
    "\n",
    "Yes, they are back. [Is it a good or a bad memory?](\"https://github.com/Strive-School/ai_mar21/blob/main/M5_Deep_Learning/D7/Custom%20DataLoader%20and%20Dataset.ipynb\")\n",
    "\n",
    "If you take a look at that notebook, you remember that to create a custom data loader you need to override some method of the `Dataset` class from `torch.utils.data`. Before doing so, let's define the steps we need to do while loading the data:\n",
    "\n",
    "- Receive as input a row from the dataframe that we have defined above, that contains two columns: \"star\" and \"review\"\n",
    "- we separate \"star\" from \"review\"\n",
    "- we preprocess the \"review\" columns by doing what we have so far (tokenization etc but excluding the embeddings for now)\n",
    "- Padding \n",
    "- Store a list containing the sequence of indices with the associated labels\n",
    "\n",
    "Then we need to override also the `__len__` and the `__getitem__`methods of the `Dataset` class.\n",
    "\n",
    "Ok, stop talking, more action:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "class TrainData(Dataset):\n",
    "    def __init__(self, df, max_seq_len=32): # df is the input df, max_seq_len is the max lenght allowed to a sentence before cutting or padding\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        counter = Counter()\n",
    "        train_iter = iter(df.review.values)\n",
    "        self.vec = FastText(\"simple\")\n",
    "        self.vec.vectors[1] = -torch.ones(self.vec.vectors[1].shape[0]) # replacing the vector associated with 1 (padded value) to become a vector of -1.\n",
    "        self.vec.vectors[0] = torch.zeros(self.vec.vectors[0].shape[0]) # replacing the vector associated with 0 (unknown) to become zeros\n",
    "        self.vectorizer = lambda x: self.vec.vectors[x]\n",
    "        self.labels = df.star\n",
    "        sequences = [padding(encoder(preprocessing(sequence), self.vec), max_seq_len) for sequence in df.review.tolist()]\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        assert len(self.sequences[i]) == self.max_seq_len\n",
    "        return self.sequences[i], self.labels[i]"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:18:56.755477Z",
     "start_time": "2021-09-18T20:18:56.751413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "dataset = TrainData(train_df, max_seq_len=32)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.328453Z",
     "start_time": "2021-09-18T20:18:56.785701Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we index dataset with a `dataset[index]` notation, we get the pair containing the padded sequence of indices with the associated label: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "dataset[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([90,\n",
       "  0,\n",
       "  631,\n",
       "  7404,\n",
       "  14711,\n",
       "  6168,\n",
       "  1924,\n",
       "  0,\n",
       "  216,\n",
       "  0,\n",
       "  5577,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 2)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.353041Z",
     "start_time": "2021-09-18T20:19:27.349795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "dataset[1][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[22986,\n",
       " 1659,\n",
       " 477,\n",
       " 34,\n",
       " 3282,\n",
       " 2225,\n",
       " 338,\n",
       " 859,\n",
       " 1753,\n",
       " 22761,\n",
       " 90,\n",
       " 297,\n",
       " 2942,\n",
       " 3680,\n",
       " 5133,\n",
       " 999,\n",
       " 1607,\n",
       " 7344,\n",
       " 690,\n",
       " 10531,\n",
       " 741,\n",
       " 906,\n",
       " 47858,\n",
       " 5487,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.380289Z",
     "start_time": "2021-09-18T20:19:27.377500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the ones there? They are the product of the padding! \n",
    "\n",
    "What is the vector associated with the index 1?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "dataset.vec.vectors[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.388716Z",
     "start_time": "2021-09-18T20:19:27.381220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All negative ones! Makes sense! This is what we have defined!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Storing into memory a lot of tensors containing all the embedded vectors, it can be very costly. This is why we load them by indexing with an integer. However, when we train our model, we need the embedded vectors!\n",
    "\n",
    "So let's define the `collate` function that will index our vocabulary only when it needs it!\n",
    "\n",
    "As argument it takes the batch (which will contains a `batch_size*max_seq_len` shape tensor) and the vectorizer. What is the vectorizer in our case? It's the vectorizer we have built in the TrainData class, that assign the vector associated with an index."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def collate(batch, vectorizer=dataset.vectorizer):\n",
    "    inputs = torch.stack([torch.stack([vectorizer(token) for token in sentence[0]]) for sentence in batch])\n",
    "    target = torch.LongTensor([item[1] for item in batch]) # Use long tensor to avoid unwanted rounding\n",
    "    return inputs, target"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.437008Z",
     "start_time": "2021-09-18T20:19:27.434752Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now, we can use the `DataLoader` class as we did for images:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.465335Z",
     "start_time": "2021-09-18T20:19:27.463197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "next(iter(train_loader))[0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 300])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.471533Z",
     "start_time": "2021-09-18T20:19:27.466451Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ready to train? Following is a small model to *makes things to run on my computer*. You can expect to be kicked out if you come at the debrief with this model! \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "emb_dim = 300\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, max_seq_len, emb_dim, hidden1=16, hidden2=16):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(max_seq_len*emb_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 5)\n",
    "        self.out = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.out(x)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.497792Z",
     "start_time": "2021-09-18T20:19:27.494432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "MAX_SEQ_LEN = 32\n",
    "model = Classifier(MAX_SEQ_LEN, 300, 16, 16)\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=9600, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=5, bias=True)\n",
       "  (out): LogSoftmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.502957Z",
     "start_time": "2021-09-18T20:19:27.499144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.570818Z",
     "start_time": "2021-09-18T20:19:27.568815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "dataiter = iter(train_loader)\n",
    "sentences, labels = dataiter.next()"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.597418Z",
     "start_time": "2021-09-18T20:19:27.593108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Forward pass through the network\n",
    "sentence_idx = 0\n",
    "sentences.resize_(16, 1, MAX_SEQ_LEN*emb_dim).shape\n",
    "log_ps = model.forward(sentences[sentence_idx,:])\n",
    "\n",
    "sentence = sentences[sentence_idx]\n",
    "torch.exp(log_ps)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2050, 0.1258, 0.1624, 0.2720, 0.2347]], grad_fn=<ExpBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:27.602693Z",
     "start_time": "2021-09-18T20:19:27.598474Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got 5 probabilities: one for each of the possible rating star!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (sentences, labels) in enumerate(iter(train_loader)):\n",
    "\n",
    "        sentences.resize_(sentences.size()[0], 32* emb_dim)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(sentences)   # 1) Forward pass\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/3\n",
      "\tIteration: 0\t Loss: 0.0397\n",
      "\tIteration: 40\t Loss: 1.6734\n",
      "\tIteration: 80\t Loss: 1.6169\n",
      "\tIteration: 120\t Loss: 1.6101\n",
      "\tIteration: 160\t Loss: 1.6115\n",
      "\tIteration: 200\t Loss: 1.6039\n",
      "\tIteration: 240\t Loss: 1.6004\n",
      "\tIteration: 280\t Loss: 1.5890\n",
      "\tIteration: 320\t Loss: 1.5909\n",
      "\tIteration: 360\t Loss: 1.6011\n",
      "\tIteration: 400\t Loss: 1.6019\n",
      "\tIteration: 440\t Loss: 1.6034\n",
      "\tIteration: 480\t Loss: 1.5870\n",
      "Epoch: 2/3\n",
      "\tIteration: 0\t Loss: 0.0387\n",
      "\tIteration: 40\t Loss: 1.5754\n",
      "\tIteration: 80\t Loss: 1.5704\n",
      "\tIteration: 120\t Loss: 1.5544\n",
      "\tIteration: 160\t Loss: 1.5138\n",
      "\tIteration: 200\t Loss: 1.5313\n",
      "\tIteration: 240\t Loss: 1.5267\n",
      "\tIteration: 280\t Loss: 1.5412\n",
      "\tIteration: 320\t Loss: 1.5371\n",
      "\tIteration: 360\t Loss: 1.5129\n",
      "\tIteration: 400\t Loss: 1.5101\n",
      "\tIteration: 440\t Loss: 1.5274\n",
      "\tIteration: 480\t Loss: 1.5114\n",
      "Epoch: 3/3\n",
      "\tIteration: 0\t Loss: 0.0365\n",
      "\tIteration: 40\t Loss: 1.4899\n",
      "\tIteration: 80\t Loss: 1.4274\n",
      "\tIteration: 120\t Loss: 1.4591\n",
      "\tIteration: 160\t Loss: 1.3636\n",
      "\tIteration: 200\t Loss: 1.3477\n",
      "\tIteration: 240\t Loss: 1.3683\n",
      "\tIteration: 280\t Loss: 1.3689\n",
      "\tIteration: 320\t Loss: 1.4126\n",
      "\tIteration: 360\t Loss: 1.3683\n",
      "\tIteration: 400\t Loss: 1.3872\n",
      "\tIteration: 440\t Loss: 1.3485\n",
      "\tIteration: 480\t Loss: 1.3885\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:28.590821Z",
     "start_time": "2021-09-18T20:19:27.626081Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eventually:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "test_dataset = TrainData(test_df, max_seq_len=32)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/111051 [00:00<?, ?it/s]WARNING:torchtext.vocab:Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      " 26%|██▌       | 28576/111051 [00:07<00:22, 3723.29it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/2976465582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/1938213561.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, max_seq_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# replacing the vector associated with 1 (padded value) to become a vector of -1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# replacing the vector associated with 0 (unknown) to become zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0;31m# Explicitly splitting on \" \" is important, so we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;31m# get rid of Unicode non-breaking spaces in the vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "test_dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.TrainData at 0x7fd96e6ca2e0>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "test_batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "next(iter(test_loader))[0].shape"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/3942671359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/1938213561.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_dataiter = iter(test_loader)\n",
    "sentences, labels = test_dataiter.next()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/457289938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/1938213561.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, (sentences, labels) in enumerate(iter(test_loader)):\n",
    "    print(sentences)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/3588517976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_26451/1938213561.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifier = Classifier(max_seq_len=32, emb_dim=300)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (sentences, labels) in enumerate(iter(test_loader)):\n",
    "        sentences.resize_(sentences.size()[0], 32* emb_dim)\n",
    "        outputs = model.forward(text)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (len(test),\n",
    "    100 * correct / total))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchtext import datasets"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:28.618668Z",
     "start_time": "2021-09-18T20:19:28.616715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train, test = datasets.AmazonReviewFull()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "amazon_review_full_csv.tar.gz: 188MB [00:15, 12.3MB/s] \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-fdd2afb5cf11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmazonReviewFull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mnew_fn\u001b[0;34m(root, split, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_check_default_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/datasets/amazonreviewfull.py\u001b[0m in \u001b[0;36mAmazonReviewFull\u001b[0;34m(root, split)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wrap_split_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAmazonReviewFull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     path = _download_extract_validate(root, URL, MD5, os.path.join(root, _PATH), os.path.join(root, _EXTRACTED_FILES[split]),\n\u001b[0m\u001b[1;32m     41\u001b[0m                                       _EXTRACTED_FILES_MD5[split], hash_type=\"md5\")\n\u001b[1;32m     42\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating {} data'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36m_download_extract_validate\u001b[0;34m(root, url, url_md5, downloaded_file, extracted_file, extracted_file_md5, hash_type)\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mextracted_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     dataset_tar = download_from_url(url, path=os.path.join(root, downloaded_file),\n\u001b[0m\u001b[1;32m    275\u001b[0m                                     hash_value=url_md5, hash_type=hash_type)\n\u001b[1;32m    276\u001b[0m     \u001b[0mextracted_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/utils.py\u001b[0m in \u001b[0;36mdownload_from_url\u001b[0;34m(url, path, root, overwrite, hash_value, hash_type)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/torchtext/utils.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(r, root, filename)\u001b[0m\n\u001b[1;32m     87\u001b[0m             with tqdm(total=total_size, unit='B',\n\u001b[1;32m     88\u001b[0m                       unit_scale=1, desc=path.split('/')[-1]) as t:\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \"\"\"\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m                 decoded = self._decode(\n\u001b[1;32m    769\u001b[0m                     \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_decoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mIncompleteRead\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/condaenv/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T20:19:46.366793Z",
     "start_time": "2021-09-18T20:19:28.668800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises\n",
    "\n",
    "- Create a real training process: use the train, val, test split for the dataset\n",
    "- Create a training loop that includes validation and test at the end\n",
    "    - You can borrow from your previous work, no need to write it from scratch\n",
    "- If you want to, feel free to change dataset\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('nlpmod': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "1338bda0d4fdf6930425270149559e14bcfa80d36c325e678f1117da69b7c09a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}